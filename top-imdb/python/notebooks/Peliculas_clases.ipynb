{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***IMDb, analizando la base de datos con clases***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZSbNDe89sZHA",
    "outputId": "96881fc4-6db9-47b7-9303-69949d11497b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo ya existe. Se omite la descarga.\n",
      "Archivo descomprimido en data\n",
      "Las 10 películas mejor calificadas:\n",
      "\n",
      "+---------------------------------+----------+-------------------------------------+\n",
      "|             Película            | Promedio |                 URL                 |\n",
      "+---------------------------------+----------+-------------------------------------+\n",
      "| Mission of Justice (Video 1992) |  10.00   | http://www.imdb.com/title/tt0104888 |\n",
      "|        Mr. Destiny (1990)       |  10.00   | http://www.imdb.com/title/tt0100201 |\n",
      "|         Chocolat (1988)         |  10.00   | http://www.imdb.com/title/tt0094868 |\n",
      "|   Love Is All There Is (1996)   |  10.00   | http://www.imdb.com/title/tt0116928 |\n",
      "|         花都舞影 (1951)         |  10.00   | http://www.imdb.com/title/tt0043278 |\n",
      "|        禁忌的星球 (1956)        |  10.00   | http://www.imdb.com/title/tt0049223 |\n",
      "|      Slaughter High (1986)      |  10.00   | http://www.imdb.com/title/tt0091969 |\n",
      "|         非法正義 (2002)         |  10.00   | http://www.imdb.com/title/tt0257044 |\n",
      "|        紫色姊妹花 (1985)        |  10.00   | http://www.imdb.com/title/tt0088939 |\n",
      "|        冰原歷險記 (2002)        |  10.00   | http://www.imdb.com/title/tt0268380 |\n",
      "+---------------------------------+----------+-------------------------------------+\n",
      "Las 10 películas peor calificadas:\n",
      "\n",
      "+-------------------------------------------+----------+-------------------------------------+\n",
      "|                  Película                 | Promedio |                 URL                 |\n",
      "+-------------------------------------------+----------+-------------------------------------+\n",
      "|             Church Ball (2006)            |   1.00   | http://www.imdb.com/title/tt0457303 |\n",
      "| Islam: What the West Needs to Know (2006) |   1.00   | http://www.imdb.com/title/tt0818682 |\n",
      "|        Dark Honeymoon (Video 2008)        |   1.00   | http://www.imdb.com/title/tt0783501 |\n",
      "|       Zi'ab la ta'kol al lahm (1973)      |   1.00   | http://www.imdb.com/title/tt0477924 |\n",
      "|           Killer Workout (1987)           |   1.00   | http://www.imdb.com/title/tt0091339 |\n",
      "|         The Cat in the Hat (2003)         |   1.00   | http://www.imdb.com/title/tt0312528 |\n",
      "|     Diary of a Sex Addict (Video 2001)    |   1.00   | http://www.imdb.com/title/tt0253040 |\n",
      "|    \"末世黑天使\" Pilot (TV Episode 2000)   |   1.00   | http://www.imdb.com/title/tt0235326 |\n",
      "|               食罪人 (2003)               |   1.00   | http://www.imdb.com/title/tt0304711 |\n",
      "|              衰腳神父 (2006)              |   1.00   | http://www.imdb.com/title/tt0462053 |\n",
      "+-------------------------------------------+----------+-------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import hashlib\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import stat\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "class IMDBAnalysis:\n",
    "    def __init__(self, url, directorio, directorio_pos, directorio_neg, urls_pos, urls_neg):\n",
    "        self.url = url\n",
    "        self.directorio = directorio\n",
    "        self.directorio_pos = directorio_pos\n",
    "        self.directorio_neg = directorio_neg\n",
    "        self.urls_pos = urls_pos\n",
    "        self.urls_neg = urls_neg\n",
    "\n",
    "    def download_database(self,url):\n",
    "      \"\"\"Descarga la base de datos desde la URL especificada.\"\"\"\n",
    "      directory = Path(\"data\")\n",
    "      directory.mkdir(parents=True, exist_ok=True)\n",
    "      tar_path = directory / \"aclImdb_v1.tar.gz\"\n",
    "\n",
    "      if not tar_path.exists():  # Si el archivo no existe, descargarlo\n",
    "          urllib.request.urlretrieve(url, tar_path)\n",
    "          print(\"Descarga completada.\")\n",
    "      else:  # Si el archivo ya existe, imprimir un mensaje\n",
    "          print(\"El archivo ya existe. Se omite la descarga.\")\n",
    "      return tar_path\n",
    "\n",
    "    def decompress_file(self,directorio):\n",
    "        \"\"\"Descomprime el archivo .tar.gz especificado.\"\"\"\n",
    "        directory = directorio.parent\n",
    "        with tarfile.open(directorio, \"r:gz\") as tar:\n",
    "            tar.extractall(path=directory)\n",
    "        print(f\"Archivo descomprimido en {directory}\")\n",
    "\n",
    "    def leer_puntuaciones(self, directorio):\n",
    "        puntuaciones = defaultdict(list)\n",
    "        for subdir, _, files in os.walk(directorio):\n",
    "            for file_name in files:\n",
    "                try:\n",
    "                    identificador, puntuacion_str = file_name.split('_')\n",
    "                    puntuacion = int(puntuacion_str.split('.')[0])\n",
    "                    puntuaciones[identificador].append(puntuacion)\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "        return puntuaciones\n",
    "\n",
    "    def calcular_promedios(self, puntuaciones):\n",
    "        promedios_conjunto = set()\n",
    "        for identificador, scores in puntuaciones.items():\n",
    "            promedio = sum(scores) / len(scores)\n",
    "            promedios_conjunto.add((identificador, promedio))  # Guardamos (película, promedio) en un conjunto\n",
    "        return promedios_conjunto\n",
    "\n",
    "    def obtener_top_n(self, promedios, n=10, mejor=True):\n",
    "        sorted_movies = sorted(promedios, key=lambda x: x[1], reverse=mejor)\n",
    "\n",
    "        peliculas_unicas = []\n",
    "        vistos = set()\n",
    "\n",
    "        for pelicula, promedio in sorted_movies:\n",
    "            if pelicula not in vistos:\n",
    "                peliculas_unicas.append((pelicula, promedio))\n",
    "                vistos.add(pelicula)\n",
    "            if len(peliculas_unicas) == n:\n",
    "                break\n",
    "\n",
    "        return peliculas_unicas\n",
    "\n",
    "    def procesar_url(self, url):\n",
    "        return url.split('/usercomments')[0]\n",
    "\n",
    "    def obtener_nombre_pelicula(self, url):\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 403:\n",
    "            return \"Acceso denegado (403 Forbidden)\"\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        title_tag = soup.find('title')\n",
    "        if title_tag:\n",
    "            return title_tag.text.replace(' - IMDb', '').strip()\n",
    "        else:\n",
    "            return \"Título no encontrado\"\n",
    "\n",
    "    def crear_dataframe(self, peliculas, urls_path):\n",
    "        urls = Path(urls_path).read_text().splitlines()\n",
    "        data = []\n",
    "        nombres_vistos = set()\n",
    "\n",
    "        for identificador, promedio in peliculas:\n",
    "            url = self.procesar_url(urls[int(identificador) - 1])\n",
    "            nombre_pelicula = self.obtener_nombre_pelicula(url)\n",
    "\n",
    "            if nombre_pelicula not in nombres_vistos:\n",
    "                nombres_vistos.add(nombre_pelicula)\n",
    "                data.append({'url': url, 'Película': nombre_pelicula, 'Promedio': promedio})\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def imprimir_peliculas(self, titulo, peliculas):\n",
    "        '''Imprime en consola el título y la lista de películas con su promedio y URL en formato de tabla.'''\n",
    "        table = PrettyTable()\n",
    "        table.field_names = [\"Película\", \"Promedio\", \"URL\"]\n",
    "        for pelicula in peliculas:\n",
    "            table.add_row([pelicula['Película'], f\"{pelicula['Promedio']:.2f}\", pelicula['url']])\n",
    "        print(titulo)\n",
    "        print(table)\n",
    "\n",
    "    def ejecutar_analisis(self):\n",
    "        # Leer puntuaciones\n",
    "        puntuaciones_pos = self.leer_puntuaciones(self.directorio_pos)\n",
    "        puntuaciones_neg = self.leer_puntuaciones(self.directorio_neg)\n",
    "\n",
    "        # Calcular promedios\n",
    "        promedios_p = self.calcular_promedios(puntuaciones_pos)\n",
    "        promedios_n = self.calcular_promedios(puntuaciones_neg)\n",
    "\n",
    "        # Obtener las 10 mejores y peores películas\n",
    "        mejores_peliculas = self.obtener_top_n(promedios_p, n=10)\n",
    "        peores_peliculas = self.obtener_top_n(promedios_n, n=10, mejor=False)\n",
    "\n",
    "        # Crear DataFrames\n",
    "        df_mejores = self.crear_dataframe(mejores_peliculas, self.urls_pos)\n",
    "        df_peores = self.crear_dataframe(peores_peliculas, self.urls_neg)\n",
    "\n",
    "        while len(df_mejores) < 10:\n",
    "            n_a_row = pd.DataFrame({'url': [''], 'Película': ['N/A'], 'Promedio': [0]})\n",
    "            df_mejores = pd.concat([df_mejores, n_a_row], ignore_index=True)\n",
    "\n",
    "        while len(df_peores) < 10:\n",
    "            n_a_row = pd.DataFrame({'url': [''], 'Película': ['N/A'], 'Promedio': [0]})\n",
    "            df_peores = pd.concat([df_peores, n_a_row], ignore_index=True)\n",
    "\n",
    "        self.imprimir_peliculas(\"Las 10 películas mejor calificadas:\\n\", df_mejores.to_dict(orient='records'))\n",
    "        self.imprimir_peliculas(\"Las 10 películas peor calificadas:\\n\", df_peores.to_dict(orient='records'))\n",
    "\n",
    "def main():\n",
    "    url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "    # Define directorios y archivos de URLs usando el directorio de trabajo actual\n",
    "    base_dir = Path.cwd() / 'data' / 'aclImdb' / 'train'\n",
    "    directorio_pos = base_dir / 'pos'\n",
    "    directorio_neg = base_dir / 'neg'\n",
    "    urls_pos = base_dir / 'urls_pos.txt'  # Ruta relativa\n",
    "    urls_neg = base_dir / 'urls_neg.txt'  # Ruta relativa\n",
    "    # Ejecutar el análisis\n",
    "    analysis = IMDBAnalysis(url, base_dir, directorio_pos, directorio_neg, urls_pos, urls_neg)\n",
    "    tar_file = analysis.download_database(url)\n",
    "    analysis.decompress_file(tar_file)\n",
    "    analysis.ejecutar_analisis()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
