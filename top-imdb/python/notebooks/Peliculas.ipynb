{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zl6KRwgwjxa2"
   },
   "source": [
    "# ***IMDb, analizando la base de datos***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0W_2n0oQWiD"
   },
   "source": [
    "Importamos las librerías necesarias;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prettytable\n",
      "  Downloading prettytable-3.11.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prettytable) (0.2.8)\n",
      "Downloading prettytable-3.11.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NSDoPH8MJsYV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import hashlib\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import stat\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jG5AnLuHJtNt"
   },
   "source": [
    "1. Función para descargar el Large Movie Review Database a un directorio dado, si el archivo ya existe, omitir la descarga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fHw7mH-JJzD8"
   },
   "outputs": [],
   "source": [
    "def download_database(url, directory):\n",
    "    archivo = os.path.join(directorio, os.path.basename(url))\n",
    "    os.makedirs(os.path.dirname(archivo), exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(archivo): # Si el archivo no existe, descargarlo\n",
    "        urllib.request.urlretrieve(url, archivo)\n",
    "        print(\"Descarga completada.\")\n",
    "    else: # Si el archivo ya existe, imprimir un mensaje\n",
    "        print(\"El archivo ya existe. Se omite la descarga.\")\n",
    "    return archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtEQO9nPJ80r"
   },
   "source": [
    "2. Función que descomprime el archivo en el mismo directorio, de tal manera que obtengas el directorio de la base de datos y el archivo con extensión `.tar.gz` en el mismo directorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PSla8ar4KEjd"
   },
   "outputs": [],
   "source": [
    "def decompress_file(file, directory):\n",
    "    try:\n",
    "        with tarfile.open(file, \"r:gz\") as tar:\n",
    "            tar.extractall(path=directory)\n",
    "        print(f\"Descomprimido en {directory}.\")\n",
    "    except EOFError:\n",
    "        print(\"Por favor, vuelve a descargar el archivo e inténtalo de nuevo.\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPltq-oJO3vs"
   },
   "source": [
    "3. A continuación se implementan las funciones necesarias para encontrar las 10 películas peor calificadas en promedio y las 10 películas mejor calificadas en promedio del directorio `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vik8moSkO3D6",
    "outputId": "9717dee1-76ef-4bf6-f648-deb18ebf95c2"
   },
   "outputs": [],
   "source": [
    "def leer_puntuaciones(directorio):\n",
    "    \"\"\"Lee los archivos en el directorio especificado y devuelve un diccionario con las puntuaciones por identificador de película.\"\"\"\n",
    "    puntuaciones = defaultdict(list)\n",
    "\n",
    "    # Recorrer archivos en subdirectorios de train (ej: train/pos y train/neg)\n",
    "    for subdir, _, files in os.walk(directorio):\n",
    "        for file_name in files:\n",
    "            file_path = Path(subdir) / file_name\n",
    "            try:\n",
    "                # Extraer identificador y puntuación (asumiendo formato 'id_score.txt')\n",
    "                identificador, puntuacion_str = file_name.split('_')\n",
    "                puntuacion = int(puntuacion_str.split('.')[0])\n",
    "                puntuaciones[identificador].append(puntuacion)\n",
    "            except (ValueError, IndexError):\n",
    "                # Omitir archivos que no cumplan con el formato esperado\n",
    "                print(f\"Archivo omitido: {file_name} (no tiene un formato válido)\")\n",
    "                continue\n",
    "\n",
    "    return puntuaciones\n",
    "\n",
    "def calcular_promedios(puntuaciones):\n",
    "    \"\"\"Calcula el promedio de puntuaciones por identificador de película.\"\"\"\n",
    "    promedios = {identificador: sum(scores) / len(scores) for identificador, scores in puntuaciones.items()}\n",
    "    return promedios\n",
    "\n",
    "def obtener_top_n(promedios, n=10, mejor=True):\n",
    "    \"\"\"Obtiene las n mejores o peores películas en función del promedio de puntuaciones.\"\"\"\n",
    "    return sorted(promedios.items(), key=lambda x: x[1], reverse=mejor)[:n]\n",
    "\n",
    "def procesar_url(url):\n",
    "    \"\"\"Extrae la parte de la URL que contiene el título de la película.\"\"\"\n",
    "    return url.split('/usercomments')[0]\n",
    "\n",
    "def obtener_nombre_pelicula(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 403:\n",
    "        return \"Acceso denegado (403 Forbidden)\"\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title_tag = soup.find('title')\n",
    "    if title_tag:\n",
    "        return title_tag.text.replace(' - IMDb', '').strip()\n",
    "    else:\n",
    "        return \"Título no encontrado\"\n",
    "\n",
    "def crear_dataframe(peliculas, urls_path):\n",
    "    \"\"\"Crea un DataFrame con la información de las películas.\"\"\"\n",
    "    urls = Path(urls_path).read_text().splitlines()\n",
    "    data = []\n",
    "\n",
    "    for identificador, promedio in peliculas:\n",
    "        url = procesar_url(urls[int(identificador) - 1])\n",
    "        data.append({'url': url, 'Película': obtener_nombre_pelicula(url), 'Promedio': promedio})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def imprimir_peliculas(titulo, peliculas):\n",
    "        '''Imprime en consola el título y la lista de películas con su promedio y URL en formato de tabla.'''\n",
    "        table = PrettyTable()\n",
    "        table.field_names = [\"Película\", \"Promedio\", \"URL\"]\n",
    "        for pelicula in peliculas:\n",
    "            table.add_row([pelicula['Película'], f\"{pelicula['Promedio']:.2f}\", pelicula['url']])\n",
    "        print(titulo)\n",
    "        print(table)\n",
    "\n",
    "def peliculas(directorio_pos, directorio_neg, urls_pos, urls_neg):\n",
    "        # Leer puntuaciones\n",
    "        puntuaciones_pos = leer_puntuaciones(directorio_pos)\n",
    "        puntuaciones_neg = leer_puntuaciones(directorio_neg)\n",
    "\n",
    "        # Calcular promedios\n",
    "        promedios_p = calcular_promedios(puntuaciones_pos)\n",
    "        promedios_n = calcular_promedios(puntuaciones_neg)\n",
    "\n",
    "        # Obtener las 10 mejores y peores películas\n",
    "        mejores_peliculas = obtener_top_n(promedios_p)\n",
    "        peores_peliculas = obtener_top_n(promedios_n, mejor=False)\n",
    "\n",
    "        # Crear DataFrames\n",
    "        df_mejores = crear_dataframe(mejores_peliculas, urls_pos)\n",
    "        df_peores = crear_dataframe(peores_peliculas, urls_neg)\n",
    "\n",
    "        while len(df_mejores) < 10:\n",
    "            n_a_row = pd.DataFrame({'url': [''], 'Película': ['N/A'], 'Promedio': [0]})\n",
    "            df_mejores = pd.concat([df_mejores, n_a_row], ignore_index=True)\n",
    "\n",
    "        while len(df_peores) < 10:\n",
    "            n_a_row = pd.DataFrame({'url': [''], 'Película': ['N/A'], 'Promedio': [0]})\n",
    "            df_peores = pd.concat([df_peores, n_a_row], ignore_index=True)\n",
    "\n",
    "        imprimir_peliculas(\"Las 10 películas mejor calificadas:\\n\", df_mejores.to_dict(orient='records'))\n",
    "        imprimir_peliculas(\"Las 10 películas peor calificadas:\\n\", df_peores.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio principal de reseñas y archivo de URLs\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "directorio = \"./downloads/basedatos/aclImdb\"\n",
    "directorio_pos = './downloads/basedatos/aclImdb/aclImdb/train/pos'\n",
    "directorio_neg = './downloads/basedatos/aclImdb/aclImdb/train/neg'\n",
    "urls_pos = './downloads/basedatos/aclImdb/aclImdb/train/urls_pos.txt'\n",
    "urls_neg = './downloads/basedatos/aclImdb/aclImdb/train/urls_neg.txt'\n",
    "archivo = download_database(url, directorio)\n",
    "decompress_file(archivo, directorio)\n",
    "peliculas(directorio_pos, directorio_neg, urls_pos, urls_neg)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
